{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sieci neuronowe projekt 1.\n",
    " ## Temat projektu\n",
    " Rozpoznawanie jakości wina na podstawie jego właściwośći fizykochemicznych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "data = pd.read_csv('winequality//winequality-white.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Wektor danych wejściowych\n",
    " Na wejściu mamy wektor 12 wymiarowy. Pierwsze 11 wymiarów to wartości wejściowe, ostatni - 12 - to jest jakość wina czyli jego wartość wyjściowa.\n",
    " Wektor danych wygląda następująco:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Podział danych\n",
    " Najpierw oddzielamy dane wejściowe od danych wejściowych, następnie dzielimy dataset\n",
    " na dane treningowe i dane testowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.quality\n",
    "X = data.drop('quality',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Podział 80%-20%\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Podział 90%-10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Standaryzacja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7d8ae9b89377>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_train_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_test_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "sc = preprocessing.StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Podział 70%-30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Dobór parametrów modelu\n",
    "\n",
    " Do wybrania funkcji aktywacji użyliśmy kolejno wszystkich możliwych i wybraliśmy funkcję, która\n",
    " daje najlepsze rezultaty.\n",
    "\n",
    " Za solver wybraliśmy parametr 'lbfgs' , ponieważ jest on zalecany do mniejszych datasetów\n",
    "\n",
    "\n",
    " TODO: POMYŚLEC NAD alpha : float, optional, default 0.0001\n",
    "\n",
    " Parametrów: learning_rate_init, power_t, shuffle, momentum, nesterovs_momentum, early_stopping, validation_fraction, beta_1, beta_2, epsilon, n_iter_no_change nie używaliśmy.\n",
    " Wykluczają się one z naszym solverem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oszacowanie aktywacji\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "activations = ['identity', 'logistic', 'tanh', 'relu']\n",
    "for item in activations:\n",
    "    classifier = MLPClassifier(solver='lbfgs', alpha=1e-5,activation=item,\n",
    "                               hidden_layer_sizes=(500,100), random_state=1,\n",
    "                               max_iter=1000)\n",
    "    classifier.fit(X_train_std,y_train)\n",
    "    print('Training set score: {} %'.format(classifier.score(X_train_std,y_train)*100))\n",
    "    print('Training set loss: {} %'.format(classifier.loss_*100))\n",
    "    print('Test accuracy: {}%'.format(classifier.score(X_test_std,y_test)*100))\n",
    "    # classifier.predict(x)\n",
    "    # classifier.predict()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
